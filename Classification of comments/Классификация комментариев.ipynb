{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from lightgbm import LGBMClassifier \n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работаем с датасетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n",
      "None\n",
      "---------------------\n",
      "   Unnamed: 0                                               text  toxic\n",
      "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
      "1           1  D'aww! He matches this background colour I'm s...      0\n",
      "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
      "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
      "4           4  You, sir, are my hero. Any chance you remember...      0\n",
      "---------------------\n",
      "Unnamed: 0    0\n",
      "text          0\n",
      "toxic         0\n",
      "dtype: int64\n",
      "---------------------\n",
      "0\n",
      "---------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.info())\n",
    "print('---------------------')\n",
    "print(df.head())\n",
    "print('---------------------')\n",
    "print(df.isna().sum())\n",
    "print('---------------------')\n",
    "print(df.duplicated().sum())\n",
    "print('---------------------')\n",
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Промежуточный вывод. Датасет содержит 159292 записи. Явных дубликатов и пропусков значений нет. Содержит 3 столбца - unnamed, text, toxic. В колонке text содержатся тексты комментариев, а в столбце toxic булевые значения является ли данный комментарий токсичным или нет (0- нет, 1 - да). Тексты комментариев на английском языке. Целевой признак - toxic. Столбец unnamed лишний, так как он дублирует индексы. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию для обработки текстов комментариев c помощью регулярных выражений для дальнейшего исследования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.37 s, sys: 93.5 ms, total: 8.46 s\n",
      "Wall time: 8.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['text'] = df['text'].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he matches this background colour i am s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i am really not trying to edit war it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i cannot make any real suggestions on imp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits made under my userna...      0\n",
       "1  d aww he matches this background colour i am s...      0\n",
       "2  hey man i am really not trying to edit war it ...      0\n",
       "3  more i cannot make any real suggestions on imp...      0\n",
       "4  you sir are my hero any chance you remember wh...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод по п.1. Данные загружены, исследованы и подготовлены. Пропусков и явных дубликатов значений не выявлено. Столбец unnamed удален. Тексты комментариев обработаны с помощью регулярных выражений. Дисбаланс классов в целевом признаке. Дальше подумаем, что с этим можно сделать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию РОS-тэгирования слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,               \n",
    "                \"N\": wordnet.NOUN,              \n",
    "                \"V\": wordnet.VERB,              \n",
    "                \"R\": wordnet.ADV               \n",
    "               }  \n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию леммализации тектов постов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_text(text):\n",
    "    text = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text)]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 8s, sys: 1min 39s, total: 18min 48s\n",
      "Wall time: 18min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df['text'] = df['text'].apply(lemm_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на признаки (матрица X) и целевую переменную (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('toxic', axis=1)\n",
    "y = df['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем параметры с помощью GridSearchCV с расчетом TF-IDF для моделей LogisticRegression и LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель LogisticRegression. Добавил функцию получения лучшей метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 10, 'clf__class_weight': 'balanced'}\n",
      "0.7658551782783536\n",
      "CPU times: user 12min 11s, sys: 10min 16s, total: 22min 28s\n",
      "Wall time: 22min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,3), min_df=3, max_df=0.9, use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1, stop_words=stopwords)),\n",
    "    ('clf', LogisticRegression(random_state=12345))])\n",
    "\n",
    "params = {'clf__C': [0.1, 1, 10, 100],\n",
    "          'clf__class_weight': ['balanced', None]}\n",
    "\n",
    "lr_grid = GridSearchCV(estimator=lr_pipe, param_grid=params, cv=3, \\\n",
    "                       scoring='f1', n_jobs=-1, refit=False)\n",
    "lr_grid.fit(X_train['text'], y_train)\n",
    "lr_best_paramms = lr_grid.best_params_\n",
    "\n",
    "print(lr_best_paramms)\n",
    "print(lr_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Модель LGBMClassifier. Добавил функцию получения лучшей метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lgb_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,3), min_df=3, max_df=0.9, use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1, stop_words=stopwords)),\n",
    "    ('clf', LGBMClassifier(random_state=12345))])\n",
    "\n",
    "params = {\n",
    "  'clf__n_estimators': [200],\n",
    "  'clf__learning_rate': [0.15, 0.25],\n",
    "  'clf__max_depth': [8, 10, -1]}\n",
    "\n",
    "lgb_grid = GridSearchCV(estimator=lgb_pipe, param_grid=params, cv=3, \\\n",
    "                        scoring='f1', n_jobs=-1, refit=False)\n",
    "lgb_grid.fit(X_train['text'], y_train)\n",
    "lgb_best_params = lgb_grid.best_params_\n",
    "\n",
    "print(lgb_best_params)\n",
    "print(lgb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизуем текст, преобразуем его в числовой вид"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = TfidfVectorizer(ngram_range=(1,3),\n",
    "               min_df=3, max_df=0.9, use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1, stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorize.fit_transform(X_train['text'])\n",
    "X_test = vectorize.transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Тест модели LogisticRegression с лучшей метрикой F1 с подобранными гиперпараметрами**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель  LogisticRegression, протестируем предсказания модели и полученим значение матрики качества F1 на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_m = LogisticRegression(C=10, class_weight='balanced', random_state=12345)\n",
    "lr_m.fit(X_train, y_train)\n",
    "\n",
    "test_pred = lr_m.predict(X_test)\n",
    "test_f1 = f1_score(y_test, test_pred)\n",
    "\n",
    "#def scoring(fitted_model):\n",
    "    #test_pred = fitted_model.predict(X_test)\n",
    "    #test_f1 = f1_score(y_test, test_pred)\n",
    "    \n",
    "print('F1 on test: {:.3f}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод по п.2. Выбраны модели LogisticRegression и LGBMClassifier для дальнейшего исследования. Подобраны лучшие гиперпараметры к моделям, проведено тестирование лучшей модели. Получена метрика качества модели на тестовой выборке. Она удовлетворяют условию поставленной задачи, лучшей является модель LogisticRegression с метрикой F1 = 0.785."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общий вывод. \n",
    "При выполнении проекта были загружены, исследованы и подготовлены данные с разметкой о токсичности правок от интернет-магазина \"Викишоп\". Удалены лишние колонки, тексты комментариев обработаны с помощью регулярных выражений. Для обучения выбраны модели LogisticRegression и LGBMClassifier, к ним, с помощью GridSearchCV, подобраны лучшие гиперпараметры. Для тестирования выбрана модель LogisticRegression с лучшей метрикой F1. Полученный результат не меньше 0.75 как и было установлено заданием проекта. Рекомендую в качестве инструмента для поиска токсичных комментариев модель LogisticRegression."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 251,
    "start_time": "2023-05-17T15:03:51.791Z"
   },
   {
    "duration": 1708,
    "start_time": "2023-05-17T15:04:56.452Z"
   },
   {
    "duration": 2413,
    "start_time": "2023-05-17T15:05:49.391Z"
   },
   {
    "duration": 202,
    "start_time": "2023-05-17T15:07:21.521Z"
   },
   {
    "duration": 200,
    "start_time": "2023-05-17T15:07:29.307Z"
   },
   {
    "duration": 61,
    "start_time": "2023-05-17T15:07:43.725Z"
   },
   {
    "duration": 74,
    "start_time": "2023-05-17T15:07:56.984Z"
   },
   {
    "duration": 60,
    "start_time": "2023-05-17T15:08:41.296Z"
   },
   {
    "duration": 64,
    "start_time": "2023-05-17T15:10:06.120Z"
   },
   {
    "duration": 72,
    "start_time": "2023-05-17T15:10:40.720Z"
   },
   {
    "duration": 275,
    "start_time": "2023-05-17T15:11:15.066Z"
   },
   {
    "duration": 262,
    "start_time": "2023-05-17T15:13:20.564Z"
   },
   {
    "duration": 10,
    "start_time": "2023-05-17T15:24:53.010Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-17T15:27:09.152Z"
   },
   {
    "duration": 4499,
    "start_time": "2023-05-17T15:27:29.362Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-17T15:27:50.144Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-17T15:30:03.811Z"
   },
   {
    "duration": 3188,
    "start_time": "2023-05-17T15:30:11.621Z"
   },
   {
    "duration": 6,
    "start_time": "2023-05-17T15:30:14.811Z"
   },
   {
    "duration": 8188,
    "start_time": "2023-05-17T15:33:21.753Z"
   },
   {
    "duration": 7158,
    "start_time": "2023-05-17T15:33:35.292Z"
   },
   {
    "duration": 6,
    "start_time": "2023-05-17T15:33:42.452Z"
   },
   {
    "duration": 10,
    "start_time": "2023-05-17T15:47:42.689Z"
   },
   {
    "duration": 11,
    "start_time": "2023-05-17T15:47:46.905Z"
   },
   {
    "duration": 1489,
    "start_time": "2023-05-17T15:48:05.349Z"
   },
   {
    "duration": 868,
    "start_time": "2023-05-17T15:48:06.841Z"
   },
   {
    "duration": 276,
    "start_time": "2023-05-17T15:48:07.711Z"
   },
   {
    "duration": 18,
    "start_time": "2023-05-17T15:48:07.989Z"
   },
   {
    "duration": 36,
    "start_time": "2023-05-17T15:48:08.009Z"
   },
   {
    "duration": 7724,
    "start_time": "2023-05-17T15:48:08.047Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-17T15:48:15.773Z"
   },
   {
    "duration": 20,
    "start_time": "2023-05-17T15:48:15.783Z"
   },
   {
    "duration": 28,
    "start_time": "2023-05-17T15:48:15.804Z"
   },
   {
    "duration": 1617,
    "start_time": "2023-05-17T16:07:19.407Z"
   },
   {
    "duration": 896,
    "start_time": "2023-05-17T16:07:21.026Z"
   },
   {
    "duration": 295,
    "start_time": "2023-05-17T16:07:21.924Z"
   },
   {
    "duration": 14,
    "start_time": "2023-05-17T16:07:22.220Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-17T16:07:22.236Z"
   },
   {
    "duration": 7841,
    "start_time": "2023-05-17T16:07:22.241Z"
   },
   {
    "duration": 18,
    "start_time": "2023-05-17T16:07:30.084Z"
   },
   {
    "duration": 47,
    "start_time": "2023-05-17T16:07:30.104Z"
   },
   {
    "duration": 50,
    "start_time": "2023-05-17T16:07:30.153Z"
   },
   {
    "duration": 1435021,
    "start_time": "2023-05-17T16:07:30.204Z"
   },
   {
    "duration": 91,
    "start_time": "2023-05-17T16:31:25.227Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-17T16:31:25.320Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-17T16:31:25.321Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-17T16:31:25.322Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-17T16:31:25.323Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-17T16:31:25.324Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-17T16:31:25.325Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-17T16:31:25.326Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-17T16:31:25.327Z"
   },
   {
    "duration": 1676,
    "start_time": "2023-05-17T16:59:22.123Z"
   },
   {
    "duration": 860,
    "start_time": "2023-05-17T16:59:23.802Z"
   },
   {
    "duration": 301,
    "start_time": "2023-05-17T16:59:24.663Z"
   },
   {
    "duration": 13,
    "start_time": "2023-05-17T16:59:24.966Z"
   },
   {
    "duration": 16,
    "start_time": "2023-05-17T16:59:24.981Z"
   },
   {
    "duration": 7854,
    "start_time": "2023-05-17T16:59:24.999Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-17T16:59:32.854Z"
   },
   {
    "duration": 22,
    "start_time": "2023-05-17T16:59:32.863Z"
   },
   {
    "duration": 43,
    "start_time": "2023-05-17T16:59:32.887Z"
   },
   {
    "duration": 425,
    "start_time": "2023-05-17T16:59:32.933Z"
   },
   {
    "duration": 192,
    "start_time": "2023-05-17T16:59:33.361Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-17T16:59:33.555Z"
   },
   {
    "duration": 25441,
    "start_time": "2023-05-17T16:59:33.559Z"
   },
   {
    "duration": 70908,
    "start_time": "2023-05-17T16:59:59.002Z"
   },
   {
    "duration": 1396643,
    "start_time": "2023-05-17T17:01:09.912Z"
   },
   {
    "duration": 2,
    "start_time": "2023-05-17T17:24:26.557Z"
   },
   {
    "duration": 42,
    "start_time": "2023-05-17T17:24:26.561Z"
   },
   {
    "duration": 8241,
    "start_time": "2023-05-17T17:24:26.605Z"
   },
   {
    "duration": 63,
    "start_time": "2023-05-17T17:31:10.226Z"
   },
   {
    "duration": 1462,
    "start_time": "2023-05-17T17:31:33.318Z"
   },
   {
    "duration": 859,
    "start_time": "2023-05-17T17:31:34.782Z"
   },
   {
    "duration": 276,
    "start_time": "2023-05-17T17:31:35.642Z"
   },
   {
    "duration": 13,
    "start_time": "2023-05-17T17:31:35.920Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-17T17:31:35.935Z"
   },
   {
    "duration": 7675,
    "start_time": "2023-05-17T17:31:35.945Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-17T17:31:43.621Z"
   },
   {
    "duration": 13,
    "start_time": "2023-05-17T17:31:43.630Z"
   },
   {
    "duration": 29,
    "start_time": "2023-05-17T17:31:43.645Z"
   },
   {
    "duration": 1391,
    "start_time": "2023-05-17T17:52:33.260Z"
   },
   {
    "duration": 872,
    "start_time": "2023-05-17T17:52:34.653Z"
   },
   {
    "duration": 276,
    "start_time": "2023-05-17T17:52:35.526Z"
   },
   {
    "duration": 12,
    "start_time": "2023-05-17T17:52:35.804Z"
   },
   {
    "duration": 24,
    "start_time": "2023-05-17T17:52:35.818Z"
   },
   {
    "duration": 7524,
    "start_time": "2023-05-17T17:52:35.843Z"
   },
   {
    "duration": 7,
    "start_time": "2023-05-17T17:52:43.369Z"
   },
   {
    "duration": 19,
    "start_time": "2023-05-17T17:52:43.378Z"
   },
   {
    "duration": 28,
    "start_time": "2023-05-17T17:52:43.398Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-17T17:52:43.427Z"
   },
   {
    "duration": 23855,
    "start_time": "2023-05-17T17:52:43.432Z"
   },
   {
    "duration": 162,
    "start_time": "2023-05-17T17:53:07.289Z"
   },
   {
    "duration": 63,
    "start_time": "2023-05-17T17:53:07.453Z"
   },
   {
    "duration": 68395,
    "start_time": "2023-05-17T17:53:07.518Z"
   },
   {
    "duration": 1585,
    "start_time": "2023-05-17T17:56:35.910Z"
   },
   {
    "duration": 857,
    "start_time": "2023-05-17T17:56:37.497Z"
   },
   {
    "duration": 293,
    "start_time": "2023-05-17T17:56:38.355Z"
   },
   {
    "duration": 13,
    "start_time": "2023-05-17T17:56:38.650Z"
   },
   {
    "duration": 10,
    "start_time": "2023-05-17T17:56:38.665Z"
   },
   {
    "duration": 7866,
    "start_time": "2023-05-17T17:56:38.676Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-17T17:56:46.544Z"
   },
   {
    "duration": 20,
    "start_time": "2023-05-17T17:56:46.554Z"
   },
   {
    "duration": 43,
    "start_time": "2023-05-17T17:56:46.576Z"
   },
   {
    "duration": 1406180,
    "start_time": "2023-05-17T17:56:46.622Z"
   },
   {
    "duration": 18249156,
    "start_time": "2023-05-17T18:20:12.803Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-17T23:24:21.962Z"
   },
   {
    "duration": 25774,
    "start_time": "2023-05-17T23:24:21.966Z"
   },
   {
    "duration": 68363,
    "start_time": "2023-05-17T23:24:47.743Z"
   },
   {
    "duration": 1255225,
    "start_time": "2023-05-17T23:25:56.109Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-17T23:46:51.336Z"
   },
   {
    "duration": 34,
    "start_time": "2023-05-17T23:46:51.341Z"
   },
   {
    "duration": 8130,
    "start_time": "2023-05-17T23:46:51.376Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-20T09:51:33.798Z"
   },
   {
    "duration": 47,
    "start_time": "2023-05-20T10:01:22.682Z"
   },
   {
    "duration": 1628,
    "start_time": "2023-05-20T10:01:52.909Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-20T10:02:06.577Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-20T10:02:11.602Z"
   },
   {
    "duration": 180,
    "start_time": "2023-05-20T10:02:12.312Z"
   },
   {
    "duration": 1629,
    "start_time": "2023-05-20T10:02:28.050Z"
   },
   {
    "duration": 3276,
    "start_time": "2023-05-20T10:02:29.682Z"
   },
   {
    "duration": 298,
    "start_time": "2023-05-20T10:02:32.960Z"
   },
   {
    "duration": 13,
    "start_time": "2023-05-20T10:02:33.260Z"
   },
   {
    "duration": 10,
    "start_time": "2023-05-20T10:02:33.275Z"
   },
   {
    "duration": 8288,
    "start_time": "2023-05-20T10:02:33.286Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-20T10:02:41.575Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-20T10:02:41.585Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-20T10:02:41.590Z"
   },
   {
    "duration": 498,
    "start_time": "2023-05-20T10:02:41.596Z"
   },
   {
    "duration": 10,
    "start_time": "2023-05-20T10:02:42.095Z"
   },
   {
    "duration": 25,
    "start_time": "2023-05-20T10:02:42.107Z"
   },
   {
    "duration": 1843,
    "start_time": "2023-05-20T10:04:34.579Z"
   },
   {
    "duration": 866,
    "start_time": "2023-05-20T10:04:36.424Z"
   },
   {
    "duration": 300,
    "start_time": "2023-05-20T10:04:37.293Z"
   },
   {
    "duration": 12,
    "start_time": "2023-05-20T10:04:37.595Z"
   },
   {
    "duration": 17,
    "start_time": "2023-05-20T10:04:37.609Z"
   },
   {
    "duration": 8393,
    "start_time": "2023-05-20T10:04:37.628Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-20T10:04:46.024Z"
   },
   {
    "duration": 10,
    "start_time": "2023-05-20T10:04:46.034Z"
   },
   {
    "duration": 6,
    "start_time": "2023-05-20T10:04:46.045Z"
   },
   {
    "duration": 1207295,
    "start_time": "2023-05-20T10:04:46.053Z"
   },
   {
    "duration": 10,
    "start_time": "2023-05-20T10:24:53.350Z"
   },
   {
    "duration": 38,
    "start_time": "2023-05-20T10:24:53.362Z"
   },
   {
    "duration": 1375952,
    "start_time": "2023-05-20T10:24:53.402Z"
   },
   {
    "duration": 1747,
    "start_time": "2023-05-20T12:10:06.783Z"
   },
   {
    "duration": 1007,
    "start_time": "2023-05-20T12:10:08.532Z"
   },
   {
    "duration": 411,
    "start_time": "2023-05-20T12:10:09.542Z"
   },
   {
    "duration": 15,
    "start_time": "2023-05-20T12:10:09.955Z"
   },
   {
    "duration": 6,
    "start_time": "2023-05-20T12:10:09.972Z"
   },
   {
    "duration": 9417,
    "start_time": "2023-05-20T12:10:09.979Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-20T12:10:19.398Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-20T12:10:19.408Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-20T12:10:19.425Z"
   },
   {
    "duration": 1714,
    "start_time": "2023-05-20T12:11:22.684Z"
   },
   {
    "duration": 1029,
    "start_time": "2023-05-20T12:11:24.400Z"
   },
   {
    "duration": 347,
    "start_time": "2023-05-20T12:11:25.431Z"
   },
   {
    "duration": 15,
    "start_time": "2023-05-20T12:11:25.780Z"
   },
   {
    "duration": 6,
    "start_time": "2023-05-20T12:11:25.798Z"
   },
   {
    "duration": 9496,
    "start_time": "2023-05-20T12:11:25.805Z"
   },
   {
    "duration": 7,
    "start_time": "2023-05-20T12:11:35.303Z"
   },
   {
    "duration": 30,
    "start_time": "2023-05-20T12:11:35.311Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-20T12:11:35.343Z"
   },
   {
    "duration": 68,
    "start_time": "2023-05-21T13:12:30.370Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-21T13:15:48.683Z"
   },
   {
    "duration": 49,
    "start_time": "2023-05-21T17:35:53.672Z"
   },
   {
    "duration": 2200,
    "start_time": "2023-05-21T17:37:32.614Z"
   },
   {
    "duration": 3386,
    "start_time": "2023-05-21T17:37:34.816Z"
   },
   {
    "duration": 328,
    "start_time": "2023-05-21T17:37:38.204Z"
   },
   {
    "duration": 13,
    "start_time": "2023-05-21T17:37:38.534Z"
   },
   {
    "duration": 5,
    "start_time": "2023-05-21T17:37:38.556Z"
   },
   {
    "duration": 8477,
    "start_time": "2023-05-21T17:37:38.562Z"
   },
   {
    "duration": 19,
    "start_time": "2023-05-21T17:37:47.041Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-21T17:37:47.062Z"
   },
   {
    "duration": 10,
    "start_time": "2023-05-21T17:37:47.068Z"
   },
   {
    "duration": 1129607,
    "start_time": "2023-05-21T17:37:47.082Z"
   },
   {
    "duration": 11,
    "start_time": "2023-05-21T17:56:36.691Z"
   },
   {
    "duration": 30,
    "start_time": "2023-05-21T17:56:36.704Z"
   },
   {
    "duration": 1349184,
    "start_time": "2023-05-21T17:56:36.736Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
